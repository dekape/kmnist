{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KMIST_Aug.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msc-acse/acse-8-miniproject-sigmoid/blob/oliver/KMIST_Aug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RbcJ_YgR6TU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1346
        },
        "outputId": "cbefdb5b-a7fc-474f-9b06-3af060d7353e"
      },
      "source": [
        "%pylab inline\n",
        "!pip install pycm albumentations\n",
        "!pip install pycm livelossplot\n",
        "\n",
        "from livelossplot import PlotLosses\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import time\n",
        "import random\n",
        "import copy\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n",
            "Requirement already satisfied: pycm in /usr/local/lib/python3.6/dist-packages (2.1)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.6/dist-packages (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pycm) (1.16.3)\n",
            "Requirement already satisfied: art>=1.8 in /usr/local/lib/python3.6/dist-packages (from pycm) (3.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from albumentations) (3.4.5.20)\n",
            "Collecting imgaug<0.2.7,>=0.2.5 (from albumentations)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: coverage>=4.1 in /usr/local/lib/python3.6/dist-packages (from art>=1.8->pycm) (4.5.3)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.12.0)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.3)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (4.3.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.0.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.0.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (4.4.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.46)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.5.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (41.0.1)\n",
            "Building wheels for collected packages: imgaug\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built imgaug\n",
            "Installing collected packages: imgaug\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "Successfully installed imgaug-0.2.6\n",
            "Requirement already satisfied: pycm in /usr/local/lib/python3.6/dist-packages (2.1)\n",
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: art>=1.8 in /usr/local/lib/python3.6/dist-packages (from pycm) (3.6)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pycm) (1.16.3)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from livelossplot) (5.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from livelossplot) (3.0.3)\n",
            "Requirement already satisfied: coverage>=4.1 in /usr/local/lib/python3.6/dist-packages (from art>=1.8->pycm) (4.5.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.2.4)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.6.1)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.5.3)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.3.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.5.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.4.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (0.8.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (2.10.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2.4.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook->livelossplot) (17.0.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook->livelossplot) (5.5.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook->livelossplot) (4.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook->livelossplot) (1.12.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (3.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (1.4.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.3)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->livelossplot) (2.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->livelossplot) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->livelossplot) (41.0.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (4.7.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (1.0.16)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook->livelossplot) (0.5.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.1.7)\n",
            "Cuda installed! Running on GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVR3CcngR_Kz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b2b831a-2644-448c-a543-13f3d2651e80"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B1Lg9kyQO69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = False\n",
        "\n",
        "    return True\n",
        "\t\n",
        "\t\n",
        "class CustomTensorDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, targets, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data (Tensor): A tensor containing the data e.g. images\n",
        "            targets (Tensor): A tensor containing all the labels\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample, label = self.data[idx], self.targets[idx]\n",
        "        sample = sample.view(1, 28, 28).float()\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample, label\n",
        "\n",
        "\t\t\n",
        "def normalise_image(data, mean, std):\n",
        "  \" Normalises a set of images using a given mean and standard deviation\"\n",
        "  X_norm = data[:].float()\n",
        "  X_norm = X_norm - mean\n",
        "  X_norm = X_norm / std\n",
        "  return X_norm\n",
        "\n",
        "\n",
        "class KFoldValidation(SupervisedLearning):\n",
        "    def __init__(self, X, y, model, optimiser, loss_function, batch_size, test_batch_size,\n",
        "                 device=\"cpu\", \n",
        "                 confusion_matrix=True, \n",
        "                 transform=True,\n",
        "                 seed=42, n_epochs=30,\n",
        "                 n_folds=3, \n",
        "                 early_stop = False,\n",
        "                 patience = 5,\n",
        "                 tol = 0.001):\n",
        "\n",
        "        \"\"\"\n",
        "        Class to perform a K-Fold training and validation on a model given a training dataset, an optimiser and a loss function\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: torch.tensor of size (no_images, 28, 28), training images dataset with int values between 0 and 255\n",
        "        y: torch.tensor of size (no_images), training labels with int values between 0 and 9\n",
        "        model: nn.Module or inherited class object, model to train\n",
        "        optimiser: torch.optim object with chosen optimisation technique\n",
        "        batch_size: int, size of the training batch\n",
        "        test_batch_size: int, size of validation batch\n",
        "        device: str, cpu or cuda, where to run the model\n",
        "        trasform: set to true in order to perform pre-processing with Data Augmentation\n",
        "        seed: int, seed for reproducibility\n",
        "        n_epochs: number of epochs to run the model. If early_stop is set to true, then represented the maximum number of epochs\n",
        "        val_ratio: float, positive number, ratio of training data to perform validation on\n",
        "        n_folds: int, number of stratified K folds (see scikit learn StratifiedKFold for more info)\n",
        "        early_stop: bool, if set to true will apply a stopping criteria to the model based on the relative increase in accuracy\n",
        "        patience: int, number of epochs in a stabilised accuracy necessary to call the early stop\n",
        "        tol: float, relative tolerance for the early_stop\n",
        "\t\n",
        "\tReturns\n",
        "\t-------\n",
        "\tresult: nested list [validation_loss, validation_accuracy, train_loss, train_accuracy] for each fold\n",
        "        \"\"\"\n",
        "        self.device = device\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.model_ori = model.to(self.device)\n",
        "        self.optimiser_ori = optimiser\n",
        "        \n",
        "        self.model = model.to(self.device)\n",
        "        self.optimiser = optimiser\n",
        "        self.loss_function = loss_function\n",
        "        self.X_train = None\n",
        "        self.X_val = None\n",
        "        self.y_train = None\n",
        "        self.y_val = None\n",
        "        self.transform = transform\n",
        "        \n",
        "        \n",
        "        self.result = None # The cross validation result \n",
        "        assert(batch_size > 0 and batch_size < int(0.1 * len(X)))\n",
        "        self.batch_size = batch_size\n",
        "        assert(test_batch_size > 0 and test_batch_size < int(0.1 * len(X)))\n",
        "        \n",
        "        self.test_batch_size = test_batch_size\n",
        "        self.n_epochs = n_epochs\n",
        "        self.seed = seed\n",
        "        self.n_folds = n_folds\n",
        "        \n",
        "        self.mean = None\n",
        "        self.std = None\n",
        "        \n",
        "        self.best_model = None\n",
        "        self.early_stop = early_stop\n",
        "        if self.early_stop: self.early =  early_stopping(patience=patience, rel_tol=tol)\n",
        "  \n",
        "    def cross_validation(self):\n",
        "        \"\"\"\n",
        "        Performs the KFold cross validation on the training and validation sets\n",
        "        \"\"\"\n",
        "        X = self.X/255.\n",
        "        y = self.y\n",
        "        X_train_set = []\n",
        "        y_train_set = []\n",
        "        X_val_set = []\n",
        "        y_val_set = []\n",
        "        result = []\n",
        "        \n",
        "        \n",
        "        # Store the initial state\n",
        "        init_state = copy.deepcopy(self.model_ori.state_dict())\n",
        "        init_state_opt = copy.deepcopy(self.optimiser_ori.state_dict())\n",
        "        \n",
        "        # K-fold split\n",
        "        skf = StratifiedKFold(n_splits= self.n_folds, random_state= self.seed, shuffle=False)\n",
        "        skf.get_n_splits(X, y)\n",
        "        for train_index, test_index in skf.split(X, y):\n",
        "            print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "            X_train_set.append(X[train_index]) \n",
        "            X_val_set.append(X[test_index])\n",
        "            y_train_set.append(y[train_index])\n",
        "            y_val_set.append(y[test_index])\n",
        "        \n",
        "        \n",
        "        for i, data in enumerate(X_train_set):\n",
        "            self.mean = data.numpy().mean(axis=(0,1,2))#/255\n",
        "            self.std = data.numpy().std(axis=(0,1,2))#/255\n",
        "            print(self.mean,\" \" ,self.std)\n",
        "            \n",
        "            # create train_transform\n",
        "            if self.transform:\n",
        "                train_transform =  transforms.Compose([\n",
        "                                  transforms.ToPILImage(),\n",
        "                                  transforms.RandomRotation(10),\n",
        "                                  transforms.RandomCrop(28, pad_if_needed=True),\n",
        "                                  transforms.ToTensor(), \n",
        "                                  transforms.Normalize(mean=[self.mean], std=[self.std])\n",
        "                                  ])\n",
        "            else:\n",
        "                train_transform =  transforms.Compose([\n",
        "                                  transforms.Normalize(mean=[self.mean], std=[self.std])\n",
        "                                  ])\n",
        "            val_transform = transforms.Compose([\n",
        "                                transforms.Normalize(mean=[self.mean], std=[self.std])\n",
        "                                ])\n",
        "            \n",
        "            \n",
        "            # Create Datasets\n",
        "            train_set = CustomTensorDataset(X_train_set[i], y_train_set[i].long(), transform=train_transform)\n",
        "            validation_set = CustomTensorDataset(X_val_set[i], y_val_set[i].long(), transform=val_transform)\n",
        "            \n",
        "            # Reset the model \n",
        "            self.model.load_state_dict(init_state)\n",
        "            self.optimiser.load_state_dict(init_state_opt)\n",
        "            \n",
        "            result.append(self._train_validation(train_set, validation_set))\n",
        "            print(\"The \", i, \" fold finished.\")\n",
        "        ave_result = np.array(result).mean(axis=0)\n",
        "        \n",
        "        print(\" \")\n",
        "        print(\"Result:\")\n",
        "        print(\"----------------------------\")\n",
        "        print(\"Average validation loss for \", self.n_folds ,\" folds is \", ave_result[0])\n",
        "        print(\"Average validation accuracy for \", self.n_folds ,\" folds is \", ave_result[1])\n",
        "        print(\"Average train loss for \", self.n_folds ,\" folds is \", ave_result[2])\n",
        "        print(\"Average train accuracy for \", self.n_folds ,\" folds is \", ave_result[3])\n",
        "        return result\n",
        "      \n",
        "    def _train_validation(self, train_set, validation_set, plot=True):\n",
        "        \"\"\" Train model in different folds \"\"\"\n",
        "        t = time.time()\n",
        "\n",
        "        train_loader = DataLoader(train_set, batch_size= self.batch_size, shuffle=True, num_workers=4)\n",
        "        validation_loader = DataLoader(validation_set, batch_size= self.test_batch_size, shuffle=False, num_workers=4)\n",
        "        #test_loader = DataLoader(cifar_test, batch_size=test_batch_size, shuffle=False, num_workers=4)\n",
        "        if plot:\n",
        "            liveloss = PlotLosses()\n",
        "        \n",
        "        best_val_acc = 0 # Initialize the best score\n",
        "        \n",
        "        for epoch in range(self.n_epochs):\n",
        "            logs = {}\n",
        "            train_loss, train_accuracy = super().train(train_loader)\n",
        "            logs['' + 'log loss'] = train_loss.item()\n",
        "            logs['' + 'accuracy'] = train_accuracy.item()\n",
        "            validation_loss, validation_accuracy = super().validate(validation_loader)\n",
        "            logs['val_' + 'log loss'] = validation_loss.item()\n",
        "            logs['val_' + 'accuracy'] = validation_accuracy.item()\n",
        "            if plot:\n",
        "                liveloss.update(logs)\n",
        "                liveloss.draw()\n",
        "            logs['time'] = time.time() - t\n",
        "            \n",
        "            # Checking stopping criteria\n",
        "            if self.early_stop: self.early(validation_accuracy)\n",
        "                \n",
        "            # Saving the best weights    \n",
        "            if validation_accuracy.item() > best_val_acc:  \n",
        "              self.best_model = self.model\n",
        "              best_val_acc = validation_accuracy.item()\n",
        "                \n",
        "            # If the stopping criteria is met  \n",
        "            if self.early_stop:\n",
        "                if self.early.stop: \n",
        "                    #self.model = self.best_model\n",
        "                    self.logs = logs\n",
        "                    print(\"The best model is found.\")\n",
        "                    break\n",
        "            self.logs = logs\n",
        "        self.result = [validation_loss.item(), validation_accuracy.item(), train_loss.item(), train_accuracy.item()]\n",
        "        return self.result\n",
        "\n",
        "\t  \n",
        "class early_stopping:\n",
        "  \"\"\"\n",
        "  Counter to implement early stopping\n",
        "  If validation accuracy has not relative improved above\n",
        "  a absolute tolerance set by the user than it breaks the \n",
        "  training\n",
        "  If rel_tol is set to 0 it becomes a common counter\n",
        "  \"\"\"\n",
        "  def __init__(self, patience, rel_tol, verbose=True):\n",
        "\n",
        "    \n",
        "    self.patience = patience\n",
        "    self.rel_tol = rel_tol\n",
        "    self.verbose = verbose\n",
        "    self.best_score = 0\n",
        "    self.counter = 0\n",
        "    self.stop = False\n",
        "\n",
        "  \n",
        "  def __call__(self, score):\n",
        "    \n",
        "    # If the score is under the required relative tolerance\n",
        "    # increase the counter is incremented\n",
        "    if score < self.best_score * (1 + self.rel_tol):\n",
        "        self.counter += 1\n",
        "    else:\n",
        "        self.counter = 0\n",
        "        \n",
        "        \n",
        "    if score > self.best_score:\n",
        "      self.best_score = score\n",
        "\n",
        "      \n",
        "    if self.counter >= self.patience:\n",
        "      self.stop = True    \n",
        "      \n",
        "    if self.verbose:\n",
        "      print(\"Count:\", self.counter)\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "def evaluate(X_test, model, norm_mean, norm_std, ensemble=False, test_batch_size=30, test_transform=None, device=\"cpu\", save_to_csv=False, path=\"./foo.csv\"):\n",
        "      \"\"\"\n",
        "      This method takes a tensor of images and a trained model and returns the predicted labels\n",
        "      from those images\n",
        "      Params\n",
        "      ------\n",
        "        X_test: torch.tensor of size (no_images, 28, 28), test images dataset with values prenormalised between 0 and 1 (i.e. divided by 255)\n",
        "        model: nn.Module or inherited class object\n",
        "        norm_mean: float, mean value of training set to normalise the test set\n",
        "        norm_std: float, standard deviation value of the training set to normalise the test set\n",
        "        ensemble: bool, set to true if performing ensembled models, prevents Softmax to be called twice\n",
        "        test_batch_size: int, defines the size of the batch for the test datset\n",
        "        test_transform: transforms.Compose list of transforms to apply to the dataset\n",
        "        device: str, on which device to run the model, cpu or cuda\n",
        "        save_to_csv: bool, option to save predictions to csv in format (index, prediction)\n",
        "        path: str, path to save string \n",
        "        \n",
        "      Returns\n",
        "      -------\n",
        "        y_preds: np.array of predictios made on X_test by the trained model\n",
        "        \n",
        "      \"\"\"\n",
        "      model.eval()\n",
        "      model.to(device)\n",
        "      y_test = torch.zeros_like(X_test)\n",
        "      test_dataset = CustomTensorDataset(normalise_image(X_test.float(), norm_mean, norm_std), y_test, transform=test_transform)\n",
        "      test_data_loader = DataLoader(test_dataset, test_batch_size, shuffle=False)\n",
        "      \n",
        "      y_preds = []\n",
        "      for X, y in test_data_loader:\n",
        "          with torch.no_grad():\n",
        "              X, y = X.to(device), y.to(device)\n",
        "              a2 = model(X)\n",
        "              if ensemble: y_pred = a2.max(1)[1]\n",
        "              else: y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "              y_preds.append(y_pred.cpu().numpy())\n",
        "            \n",
        "      y_preds =  np.concatenate(y_preds, 0)\n",
        "      \n",
        "      sub = pd.DataFrame(data={'Category': y_preds})\n",
        "      sub.index.name = \"Id\" \n",
        "      if save_to_csv:\n",
        "        sub.to_csv(path)\n",
        "        \n",
        "      return y_preds, sub\n",
        "\n",
        "\t   \n",
        "def model_save(model, name, path, val_acc):\n",
        "  \"\"\"Saving function to keep track of models\"\"\"\n",
        "  val = str(val_acc)[2:5]\n",
        "  path = path + name + '_' + val + '.pth'\n",
        "  print(\"Saving model under:\", path)\n",
        "  torch.save(model, path)\n",
        "  return\n",
        "\n",
        "\n",
        "def model_load(path, model_name):\n",
        "  \"\"\"Loading function for models from google drive\"\"\"\n",
        "  model = torch.load(path + model_name + '.pth')\n",
        "  return model\n",
        "\n",
        "\n",
        "def param_strip(param):\n",
        "  \"\"\"Strips the key text info out of certain parameters\"\"\"\n",
        "  return str(param)[:str(param).find('(')]\n",
        "\n",
        "\n",
        "def full_save(path, name, model, optimiser, loss_function, early_stop_tol, n_epoch, lr, momentum, weight_decay, n_folds, train_trans, val_acc, val_loss, train_time, test_acc=None):\n",
        "  \"\"\"Saves the models weights and hyperparameters to a pth file and csv file\"\"\"\n",
        "  if train_trans: train_trans=\"True\"\n",
        "  else: train_trans=\"False\"\n",
        "  ind = [\"Model, Optimiser, Loss Function, Early Stop Tol, Epochs, Learning Rate, Momentum, Weight Decay, nFolds, Augmentations, Val Acc, Val Loss, Training Time, Test Acc\"]\n",
        "  row = [param_strip(model), param_strip(optimiser), param_strip(loss_function), early_stop_tol, n_epoch, lr, momentum, weight_decay, n_folds, train_trans,val_acc, val_loss, train_time, test_acc]\n",
        "  s = [str(i) for i in row] \n",
        "  row = [\",\".join(s)]\n",
        "  model_save(model, name, path, val_acc)\n",
        "  np.savetxt(path + name + '_' + str(val_acc)[2:5] + \".csv\", np.r_[ind, row], fmt='%s', delimiter=',')\n",
        "  return\n",
        "\n",
        "\n",
        "class ensemble_net(nn.Module):\n",
        "    \"\"\"A classifier class that takes individiual pretrained models \n",
        "    and aggregates their output values to create ensemble voting\n",
        "      Params\n",
        "    ------\n",
        "      models: a list of model objects\n",
        "    Returns\n",
        "    -------\n",
        "      x_out: a probability vector for the output classes\n",
        "    \"\"\"\n",
        "    def __init__(self, models):\n",
        "        super(ensemble_net, self).__init__()\n",
        "        self.models = models\n",
        "        self.soft = nn.Softmax(dim=1)\n",
        "    def forward(self, x):\n",
        "        num = len(self.models)\n",
        "        for ind, model in enumerate(self.models):\n",
        "          if ind ==0:\n",
        "            x1 = model(x)\n",
        "            x_out = self.soft(x1)\n",
        "          else:\n",
        "            x1 = model(x)\n",
        "            x_out += self.soft(x1)\n",
        "        x_out /= num\n",
        "        return x_out\n",
        "    def inspect(self):\n",
        "      \"\"\"Returns the composition of the ensemble model\"\"\"\n",
        "      for model in self.models:\n",
        "        print(model)\n",
        "      return None\n",
        "\n",
        "\n",
        "def accuracy_check(y_preds, y):\n",
        "  \"\"\"Returns the accuracy on the validation set\"\"\"\n",
        "  return len(np.where((y_preds==y.numpy())==True)[0])/len (y_preds)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_We6OtZBRnNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SupervisedLearning:\n",
        "    def __init__(self, X, y, model, optimiser, loss_function, batch_size, test_batch_size,\n",
        "                 device=\"cpu\", \n",
        "                 transform=False, \n",
        "                 seed=42, n_epochs=30,\n",
        "                 val_ratio=0.1, n_splits=1, \n",
        "                 early_stop = True,\n",
        "                 patience = 5,\n",
        "                 tol = 0.001):\n",
        "      \"\"\"\n",
        "      Class to perform training and validation on a model given a training dataset, an optimiser and a loss function\n",
        "      Parameters\n",
        "      ----------\n",
        "      X: torch.tensor of size (no_images, 28, 28), training images dataset with int values between 0 and 255\n",
        "      y: torch.tensor of size (no_images), training labels with int values between 0 and 9\n",
        "      model: nn.Module or inherited class object, model to train\n",
        "      optimiser: torch.optim object with chosen optimisation technique\n",
        "      batch_size: int, size of the training batch\n",
        "      test_batch_size: int, size of validation batch\n",
        "      device: str, cpu or cuda, where to run the model\n",
        "      trasform: set to true in order to perform pre-processing with Data Augmentation\n",
        "      seed: int, seed for reproducibility\n",
        "      n_epochs: number of epochs to run the model. If early_stop is set to true, then represented the maximum number of epochs\n",
        "      val_ratio: float, positive number, ratio of training data to perform validation on\n",
        "      n_splits: int, number of stratified shuffled spltis (see scikit learn stratified shuffle split for more info)\n",
        "      early_stop: bool, if set to true will apply a stopping criteria to the model based on the relative increase in accuracy\n",
        "      patience: int, number of epochs in a stabilised accuracy necessary to call the early stop\n",
        "      tol: float, relative tolerance for the early_stop\n",
        "      \"\"\"\n",
        "      \n",
        "      self.device = device\n",
        "      \n",
        "      self.X = X.float()/255.\n",
        "      self.y = y\n",
        "      \n",
        "      self.model = model.to(self.device)\n",
        "      self.optimiser = optimiser\n",
        "      self.loss_function = loss_function\n",
        "      \n",
        "      self.X_train = None\n",
        "      self.X_val = None\n",
        "      \n",
        "      self.y_train = None\n",
        "      self.y_val = None\n",
        "      \n",
        "      self.transform = transform\n",
        "      \n",
        "      assert(batch_size > 0 and batch_size < int(0.1 * X.size()[0]))\n",
        "      self.batch_size = batch_size\n",
        "      assert(test_batch_size > 0 and test_batch_size < int(0.1 * X.size()[0]))\n",
        "      self.test_batch_size = test_batch_size\n",
        "      self.n_epochs = n_epochs\n",
        "      self.seed = seed\n",
        "      self.val_ratio = val_ratio\n",
        "      self.n_splits = n_splits\n",
        "\n",
        "      self.trained_full=False\n",
        "      \n",
        "      self.mean_full = None\n",
        "      self.std_full = None\n",
        "      \n",
        "      self.mean = None\n",
        "      self.std = None\n",
        "      \n",
        "      self.logs = None # saves the liveloss object data\n",
        "      \n",
        "      self.best_model = None\n",
        "      \n",
        "      self.early_stop = early_stop\n",
        "      if self.early_stop: self.early =  early_stopping(patience=patience, rel_tol=tol)  \n",
        "      \n",
        "      \n",
        "    def split_data(self):\n",
        "      \"\"\"\n",
        "      Splits training data into training and validation sets given an user-specified validation ratio\n",
        "      \"\"\"\n",
        "      sss = StratifiedShuffleSplit(n_splits=self.n_splits, test_size=self.val_ratio, random_state=0)\n",
        "      sss.get_n_splits(self.X, self.y)\n",
        "\n",
        "      for train_index, val_index in sss.split(self.X, self.y):\n",
        "        self.X_train, self.X_val = self.X[train_index], self.X[val_index]\n",
        "        self.y_train, self.y_val = self.y[train_index], self.y[val_index]\n",
        "        \n",
        "      return None\n",
        "      \n",
        "      \n",
        "      \n",
        "    def train(self, train_data_loader):\n",
        "      \"\"\"\n",
        "      Trains a model given a train data loader\n",
        "      \"\"\"\n",
        "      self.model.train()                # set model to train mode\n",
        "      \n",
        "      train_loss, train_accuracy = 0., 0.\n",
        "\n",
        "      for Xtr, ytr in train_data_loader:# X and y are data inside a batch specified\n",
        "                                        # at train_data_loader\n",
        "\n",
        "        Xtr = Xtr.to(self.device)\n",
        "        ytr = ytr.to(self.device)\n",
        "        \n",
        "\n",
        "        self.optimiser.zero_grad()           # reset gradients\n",
        "        zn = self.model(Xtr)                 # perform forward pass\n",
        "        \n",
        "\n",
        "        loss = self.loss_function(zn, ytr)   # compute loss value over batch\n",
        "        loss.backward()                 # perform backward pass\n",
        "        train_loss += (loss * Xtr.size()[0]).detach().cpu().numpy()\n",
        "        \n",
        "\n",
        "        y_pred = F.log_softmax(zn, dim=1).max(1)[1]\n",
        "        train_accuracy += accuracy_score(ytr.cpu().numpy(), y_pred.detach().cpu().numpy())*Xtr.size()[0]\n",
        "        \n",
        "        self.optimiser.step()               # optimisation step\n",
        "        \n",
        "      return train_loss/len(train_data_loader.dataset), train_accuracy/len(train_data_loader.dataset)\n",
        "    \n",
        "    \n",
        "    \n",
        "    def validate(self, val_data_loader):\n",
        "      \"\"\"\n",
        "      Computes the accuracy and loss of a trained model based on a data loader\n",
        "      \"\"\"\n",
        "      self.model.eval()                     # set model to evaluation mode\n",
        "      \n",
        "      validation_loss, validation_accuracy = 0., 0.\n",
        "      \n",
        "      for Xv, yv in val_data_loader:\n",
        "        with torch.no_grad():\n",
        "          \n",
        "          Xv, yv = Xv.to(self.device), yv.to(self.device)\n",
        "          \n",
        "          zn = self.model(Xv)\n",
        "          loss = self.loss_function(zn, yv)\n",
        "          validation_loss += (loss * Xv.size(0)).detach().cpu().numpy()\n",
        "          \n",
        "          y_pred = F.log_softmax(zn, dim=1).max(1)[1]\n",
        "          validation_accuracy += accuracy_score(yv.cpu().numpy(), y_pred.detach().cpu().numpy())*Xv.size(0)\n",
        "\n",
        "            \n",
        "      return validation_loss/len(val_data_loader.dataset), validation_accuracy/len(val_data_loader.dataset)\n",
        "        \n",
        "      \n",
        "    \n",
        "    def train_wrapper(self, train_full=False, plot_loss=True):\n",
        "      \"\"\"\n",
        "      Calls class methods in order to perform training\n",
        "      Parameters\n",
        "      ----------\n",
        "      train_full: bool, if set to False, will split the data into training and validation. \n",
        "                  If true, training will be performed on the entire training dataset\n",
        "      plot_loss : bool, if set to true will plot the loss and accuracies over each epoch\n",
        "      \"\"\"\n",
        "\n",
        "      # start timer\n",
        "      t = time.time()\n",
        "      \n",
        "      # set seed\n",
        "      set_seed(int(self.seed))\n",
        "      \n",
        "      \n",
        "      if train_full: # train with full data (train + validation)\n",
        "        # find mean and std of training data\n",
        "        mean, std = self.find_mean_std(train_full)\n",
        "        \n",
        "        # create train_transform\n",
        "        if self.transform:\n",
        "          train_transform =  transforms.Compose([\n",
        "                              transforms.ToPILImage(),\n",
        "                              transforms.RandomRotation(30),\n",
        "                              transforms.RandomCrop(28, pad_if_needed=True),\n",
        "                              transforms.ToTensor(), \n",
        "                              transforms.Normalize(mean=[mean], std=[std])\n",
        "                              ])\n",
        "        else:\n",
        "          train_transform =  transforms.Compose([\n",
        "                              transforms.Normalize(mean=[mean], std=[std])\n",
        "                              ])\n",
        "        \n",
        "        # create dataloaders\n",
        "        train_dataset = CustomTensorDataset(self.X, self.y, transform=train_transform)\n",
        "        train_data_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        \n",
        "        # save best train accuracy\n",
        "        best_train_acc = 0\n",
        "        \n",
        "        # train and validate\n",
        "        if plot_loss: liveloss = PlotLosses()\n",
        "        for epoch in range(self.n_epochs):\n",
        "            logs = {}\n",
        "            train_loss, train_accuracy = self.train(train_data_loader)\n",
        "\n",
        "            if plot_loss:\n",
        "              logs['' + 'log loss'] = train_loss.item()\n",
        "              logs['' + 'accuracy'] = train_accuracy.item()\n",
        "              logs['val_' + 'log loss'] = 1.\n",
        "              logs['val_' + 'accuracy'] = 1.\n",
        "              liveloss.update(logs)\n",
        "              liveloss.draw()\n",
        "              logs['time'] = time.time() - t\n",
        "              \n",
        "            # Checking stopping criteria\n",
        "            if self.early_stop: self.early(train_accuracy)\n",
        "                \n",
        "            # Saving the best weights    \n",
        "            if train_accuracy.item() > best_train_acc:  \n",
        "              # Saving the models weights to best model\n",
        "              self.best_model = self.model\n",
        "              best_train_acc = train_accuracy.item()\n",
        "            \n",
        "            # If the stopping criteria is met  \n",
        "            if self.early_stop:\n",
        "              if self.early.stop: \n",
        "                  self.logs = logs\n",
        "                  self.model = self.best_model\n",
        "                  break\n",
        "\n",
        "            # store logs\n",
        "            self.logs = logs  \n",
        "                  \n",
        "        self.trained_full=True\n",
        "\n",
        "        # Save best model\n",
        "        self.model = self.best_model\n",
        "\n",
        "      else:\n",
        "        # split data\n",
        "        self.split_data()\n",
        "        \n",
        "        # find mean and std of training data\n",
        "        mean, std = self.find_mean_std(train_full)\n",
        "        \n",
        "        \n",
        "        # create transforms\n",
        "        if self.transform:\n",
        "          train_transform =  transforms.Compose([\n",
        "                              transforms.ToPILImage(),\n",
        "                              transforms.RandomRotation(10),\n",
        "                              transforms.RandomCrop(28, pad_if_needed=True),\n",
        "                              transforms.ToTensor(), \n",
        "                              transforms.Normalize(mean=[mean], std=[std])\n",
        "                              ])\n",
        "        else:\n",
        "          train_transform =  transforms.Compose([\n",
        "                              transforms.Normalize(mean=[mean], std=[std])\n",
        "                              ])\n",
        "        \n",
        "        # apply normalisation to validation set    \n",
        "        val_transform = transforms.Compose([\n",
        "                            transforms.Normalize(mean=[mean], std=[std])\n",
        "                            ])\n",
        "\n",
        "        # create datasets and dataloaders\n",
        "        train_dataset = CustomTensorDataset(self.X_train, self.y_train, transform=train_transform)\n",
        "        train_data_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        \n",
        "        val_dataset = CustomTensorDataset(self.X_val, self.y_val, transform=val_transform)\n",
        "        val_data_loader = DataLoader(val_dataset, batch_size=self.test_batch_size, shuffle=False)\n",
        "        \n",
        "        # store best validation accuracy\n",
        "        best_val_acc = 0\n",
        "            \n",
        "        # train and validate\n",
        "        if plot_loss: liveloss = PlotLosses()\n",
        "        for epoch in range(self.n_epochs):\n",
        "            logs = {}\n",
        "            train_loss, train_accuracy = self.train(train_data_loader)\n",
        "            val_loss, val_accuracy = self.validate(val_data_loader)\n",
        "            \n",
        "            if plot_loss:\n",
        "              logs['' + 'log loss'] = train_loss.item()\n",
        "              logs['' + 'accuracy'] = train_accuracy.item()\n",
        "              logs['val_' + 'log loss'] = val_loss.item()\n",
        "              logs['val_' + 'accuracy'] = val_accuracy.item() # liveloss wants it plotted\n",
        "              liveloss.update(logs)\n",
        "              liveloss.draw()\n",
        "              logs['time'] = time.time() - t \n",
        "            \n",
        "            # Checking stopping criteria\n",
        "            if self.early_stop: self.early(val_accuracy)\n",
        "                \n",
        "            # Saving the best weights    \n",
        "            if val_accuracy.item() > best_val_acc:  \n",
        "              self.best_model = self.model\n",
        "              best_val_acc = val_accuracy.item()\n",
        "            \n",
        "            # If the stopping criteria is met  \n",
        "            if self.early_stop:\n",
        "              if self.early.stop: \n",
        "                  self.logs = logs\n",
        "                  self.model = self.best_model\n",
        "                  break\n",
        "\n",
        "            self.logs = logs\n",
        "\n",
        "        self.trained_full=False\n",
        "        \n",
        "        # Save best model\n",
        "        self.model = self.best_model\n",
        "              \n",
        "      return None\n",
        "            \n",
        "            \n",
        "\n",
        "    def find_mean_std(self, full_training=False):\n",
        "      \"\"\"\n",
        "      Finds the mean and std values the training set\n",
        "      Mean is already relative to a prenormalised set, with values between 0 and 1\n",
        "      \"\"\"\n",
        "      mean = 0\n",
        "      std = 0\n",
        "      \n",
        "      if full_training:\n",
        "        mean = torch.mean(self.X)\n",
        "        std = torch.std(self.X)\n",
        "        \n",
        "        self.mean_full = mean\n",
        "        self.std_full = std\n",
        "        \n",
        "      else:\n",
        "        mean = torch.mean(self.X_train)\n",
        "        std = torch.std(self.X_train)\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        \n",
        "      return mean, std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFIRnl8SSM1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet5, self).__init__()\n",
        "    # The implementation of the LeNet5 architecture\n",
        "    self.c1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)\n",
        "    self.s2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.c3 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n",
        "    self.s4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.c5 = nn.Linear(16*5*5, 120)\n",
        "    self.f6 = nn.Linear(120, 84)\n",
        "    self.output = nn.Linear(84, 10)\n",
        "    self.act = nn.ReLU()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # Applying the ReLU activation function throughout the net\n",
        "    x = self.act(self.c1(x))\n",
        "    x = self.act(self.s2(x))\n",
        "    x = self.act(self.c3(x))\n",
        "    x = self.act(self.s4(x))\n",
        "    x = x.view(-1, x.size(1)*x.size(2)*x.size(3))\n",
        "    x = self.act(self.c5(x))\n",
        "    x = self.act(self.f6(x))\n",
        "    return self.output(x)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ehto15zEc4Hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNetMod(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNetMod, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 256, kernel_size=4, padding=0, stride=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), 256 * 6 * 6)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjyeST-VShT5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3f802b2e-3c90-46aa-af1d-c12be9f17773"
      },
      "source": [
        "# Import Data\n",
        "path=\"sigmoid/data/\"\n",
        "train_data = np.load(path+\"kmnist-train-imgs.npy\")\n",
        "test_data = np.load(path+\"kmnist-test-imgs.npy\")\n",
        "train_labels = np.load(path+\"kmnist-train-labels.npy\")\n",
        "classmap = pd.read_csv(path+\"kmnist_classmap.csv\")\n",
        "\n",
        "# Tensor of training data\n",
        "X = torch.from_numpy(train_data).float()\n",
        "# Tensor of training labels\n",
        "y = torch.from_numpy(train_labels).long()\n",
        "#  Tensor of test data\n",
        "X_test = torch.from_numpy(test_data).float()\n",
        "\n",
        "# Size Check\n",
        "print(\"Train Data:\", X.size())\n",
        "print(\"Test Data:\", X_test.size())\n",
        "print(\"Train Labels:\", y.size())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Data: torch.Size([60000, 28, 28])\n",
            "Test Data: torch.Size([10000, 28, 28])\n",
            "Train Labels: torch.Size([60000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nl09WIqS0H_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from albumentations import Compose, RandomCrop, Normalize, Rotate, GaussNoise, RandomContrast, ShiftScaleRotate\n",
        "from albumentations.pytorch import ToTensor\n",
        "\n",
        "albumentations_transform = Compose([\n",
        "    RandomCrop(24, 24),\n",
        "    Normalize(mean=[mean], std=[std]),\n",
        "    Rotate(limit=30, p=0.5)\n",
        "])\n",
        "\n",
        "\n",
        "# GaussNoise()\n",
        "# RandomContrast()\n",
        "# ToTensor()\n",
        "# ShiftScaleRotate(rotate_limit=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QK1e6maSiFC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "3c8bb3bc-c858-4d28-ca92-88dc642621d7"
      },
      "source": [
        "#\n",
        "# Model Name\n",
        "MODEL_NAME = \"alex_aug_full_111\"\n",
        "\n",
        "# Hyperparameters\n",
        "lr = 1e-2\n",
        "momentum = 0.5\n",
        "batch_size = 64\n",
        "test_batch_size = 1000\n",
        "n_epochs = 3\n",
        "patience=5\n",
        "early_stop_tol = 0.000\n",
        "n_folds=0\n",
        "weight_decay=0\n",
        "\n",
        "# Define/Load Model, Optimiser and Loss Function\n",
        "alexnet = model_load(\"/content/gdrive/My Drive/Sigmoid/Models/\", MODEL_NAME)\n",
        "lr_dic = []\n",
        "for i in range(0, len(alexnet.classifier)-1):\n",
        "  lr_dic.append({'params': alexnet.classifier[i].parameters(), 'lr': 0.0})\n",
        "for i in range(0, len(alexnet.features)):\n",
        "  lr_dic.append({'params': alexnet.features[i].parameters(), 'lr': 0.0})\n",
        "lr_dic.append({'params': alexnet.classifier[-1].parameters(), 'lr': lr})\n",
        "optimiser = torch.optim.SGD(lr_dic, momentum=momentum, weight_decay=0)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# Create Supervised Learning Object\n",
        "learning = SupervisedLearning(X, y, alexnet, optimiser, loss_function, batch_size, test_batch_size,\n",
        "                 device=device,\n",
        "                 transform=True, \n",
        "                 seed=42, n_epochs=n_epochs,\n",
        "                 val_ratio=0.1, n_splits=n_folds+1, \n",
        "                 early_stop = True,\n",
        "                 patience = patience,\n",
        "                 tol = early_stop_tol)\n",
        "\n",
        "# Train model with validation\n",
        "learning.train_wrapper(train_full=True)\n",
        "print(\"\\n\", learning.logs)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAE1CAYAAAD6akEFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njEbkhzIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "log loss:\n",
            "training   (min:    0.007, max:    0.009, cur:    0.007)\n",
            "validation (min:    1.000, max:    1.000, cur:    1.000)\n",
            "\n",
            "accuracy:\n",
            "training   (min:    0.997, max:    0.998, cur:    0.998)\n",
            "validation (min:    1.000, max:    1.000, cur:    1.000)\n",
            "Count: 0\n",
            "\n",
            " {'log loss': 0.006752295406659444, 'accuracy': 0.9981333333333333, 'val_log loss': 1.0, 'val_accuracy': 1.0, '_i': 3, 'time': 134.6549518108368}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnljuvadSkBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "e04e7229-d39b-4d74-8475-622df7d82401"
      },
      "source": [
        " from torchvision.datasets import KMNIST\n",
        " test = KMNIST(\"./\", train=False, download=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz to ./KMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "18169856it [00:03, 5155650.99it/s]                              \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./KMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz to ./KMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 84063.09it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./KMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz to ./KMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3047424it [00:01, 1978132.32it/s]                             \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./KMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz to ./KMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 31788.55it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./KMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frgWla5OeziA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m, s = torch.mean(X/255.), torch.std(X/255.)\n",
        "y_pred, sub = evaluate(X_test/255., alexnet, m, s, test_batch_size=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDrrdYWbfPS9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f982a5c2-051f-4e38-df5e-cffc45af2a6f"
      },
      "source": [
        "print(y_pred)\n",
        "print(m,s)\n",
        "accuracy_check(y_pred, test.targets)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 9 3 ... 9 4 2]\n",
            "tensor(0.1918) tensor(0.3483)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9722"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff4jbELufp7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}